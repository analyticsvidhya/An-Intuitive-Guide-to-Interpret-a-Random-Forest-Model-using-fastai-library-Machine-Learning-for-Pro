{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Machine Learning: Lesson 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.imports import *\n",
    "from fastai.structured import *\n",
    "from pandas_summary import DataFrameSummary\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from IPython.display import display\n",
    "from sklearn import metrics\n",
    "\n",
    "#loading preprocessed file\n",
    "PATH = \"data/bulldozers/\"\n",
    "\n",
    "df_raw = pd.read_feather('tmp/bulldozers-raw')\n",
    "df_trn, y_trn, nas = proc_df(df_raw, 'SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a validation set\n",
    "\n",
    "def split_vals(a,n): return a[:n], a[n:]\n",
    "n_valid = 12000\n",
    "n_trn = len(df_trn)-n_valid\n",
    "X_train, X_valid = split_vals(df_trn, n_trn)\n",
    "y_train, y_valid = split_vals(y_trn, n_trn)\n",
    "raw_train, raw_valid = split_vals(df_raw, n_trn)\n",
    "\n",
    "#define function to calculate rmse and print score\n",
    "def rmse(x,y): return math.sqrt(((x-y)**2).mean())\n",
    "\n",
    "def print_score(m):\n",
    "   res = [rmse(m.predict(X_train), y_train), rmse(m.predict(X_valid), y_valid),\n",
    "               m.score(X_train, y_train), m.score(X_valid, y_valid)]\n",
    "   if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n",
    "   print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_rf_samples(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a random forest model\n",
    "\n",
    "m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(t): return t.predict(X_valid)\n",
    "%time preds = np.stack(parallel_trees(m, get_preds))\n",
    "np.mean(preds[:,0]), np.std(preds[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = raw_valid.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['pred_std'] = np.std(preds, axis=0)\n",
    "x['pred'] = np.mean(preds, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence based on Tree Variance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.Enclosure.value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flds = ['Enclosure', 'SalePrice', 'pred', 'pred_std']\n",
    "enc_summ = x[flds].groupby('Enclosure', as_index=False).mean()\n",
    "enc_summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_summ = enc_summ[~pd.isnull(enc_summ.SalePrice)]\n",
    "enc_summ.plot('Enclosure', 'pred', 'barh', xerr='pred_std', alpha=0.6, xlim=(0,11));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the value count for each category\n",
    "raw_valid.ProductSize.value_counts().plot.barh();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#category wise mean for sale price, prediction and standard deviation\n",
    "flds = ['ProductSize', 'SalePrice', 'pred', 'pred_std']\n",
    "summ = x[flds].groupby(flds[0]).mean()\n",
    "summ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = rf_feat_importance(m, df_trn)\n",
    "fi[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi.plot('cols', 'imp', figsize=(10,6), legend=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fi(fi):\n",
    "return fi.plot('cols','imp','barh', figsize=(12,7), legend=False)\n",
    "plot_fi(fi[:30]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep = fi[fi.imp>0.005].cols\n",
    "len(to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keep = df_trn[to_keep].copy()\n",
    "X_train, X_valid = split_vals(df_keep, n_trn)\n",
    "\n",
    "m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features=0.5,\n",
    "n_jobs=-1, oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = rf_feat_importance(m, df_keep)\n",
    "plot_fi(fi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Machine Learning : Lesson 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn2, y_trn, nas = proc_df(df_raw, 'SalePrice', max_n_cat=7)\n",
    "X_train, X_valid = split_vals(df_trn2, n_trn)\n",
    "m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3,\n",
    "     max_features=0.6, n_jobs=-1, oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = rf_feat_importance(m, df_trn2)\n",
    "fi[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy as hc\n",
    "corr = np.round(scipy.stats.spearmanr(df_keep).correlation, 4)\n",
    "corr_condensed = hc.distance.squareform(1-corr)\n",
    "z = hc.linkage(corr_condensed, method='average')\n",
    "fig = plt.figure(figsize=(16,10))\n",
    "dendrogram = hc.dendrogram(z, labels=df_keep.columns,\n",
    "    orientation='left', leaf_font_size=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to calculate oob score\n",
    "def get_oob(df):\n",
    "  m = RandomForestRegressor(n_estimators=30, min_samples_leaf=5, max_features=0.6, n_jobs=-1, oob_score=True)\n",
    "  x, _ = split_vals(df, n_trn)\n",
    "  m.fit(x, y_train)\n",
    "  return m.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_oob(df_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ('saleYear', 'saleElapsed', 'fiModelDesc', 'fiBaseModel', 'Grouser_Tracks', 'Coupler_System'):\n",
    "  print(c, get_oob(df_keep.drop(c, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['saleYear', 'fiBaseModel', 'Grouser_Tracks']\n",
    "get_oob(df_keep.drop(to_drop, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keep.drop(to_drop, axis=1, inplace=True)\n",
    "X_train, X_valid = split_vals(df_keep, n_trn)\n",
    "reset_rf_samples()\n",
    "\n",
    "m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdpbox import pdp\n",
    "from plotnine import *\n",
    "\n",
    "set_rf_samples(50000)\n",
    "\n",
    "df_trn2, y_trn, nas = proc_df(df_raw, 'SalePrice', max_n_cat=7)\n",
    "X_train, X_valid = split_vals(df_trn2, n_trn)\n",
    "m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features=0.6, n_jobs=-1)\n",
    "m.fit(X_train, y_train);\n",
    "\n",
    "plot_fi(rf_feat_importance(m, df_trn2)[:10]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.plot('YearMade', 'saleElapsed', 'scatter', alpha=0.01, figsize=(10,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = get_sample(df_raw[df_raw.YearMade>1930], 500)\n",
    "ggplot(x_all, aes('YearMade', 'SalePrice'))+stat_smooth(se=True, method='loess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = get_sample(X_train[X_train.YearMade>1930], 500)\n",
    "\n",
    "def plot_pdp(feat, clusters=None, feat_name=None):\n",
    "   feat_name = feat_name or feat\n",
    "   p = pdp.pdp_isolate(m, x, feat)\n",
    "   return pdp.pdp_plot(p, feat_name, plot_lines=True, cluster=clusters is not None, n_cluster_centers=clusters)\n",
    "\n",
    "plot_pdp('YearMade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pdp(['Enclosure_EROPS w AC', 'Enclosure_EROPS', 'Enclosure_OROPS'], 5, 'Enclosure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from treeinterpreter import treeinterpreter as ti\n",
    "df_train, df_valid = split_vals(df_raw[df_keep.columns], n_trn)\n",
    "row = X_valid.values[None,0]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, bias, contributions = ti.predict(m, row)\n",
    "prediction[0], bias[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = np.argsort(contributions[0])\n",
    "[o for o in zip(df_keep.columns[idxs], df_valid.iloc[0][idxs], contributions[0][idxs])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Machine Learning : Lesson 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ext = df_keep.copy()\n",
    "df_ext['is_valid'] = 1\n",
    "df_ext.is_valid[:n_trn] = 0\n",
    "x, y, nas = proc_df(df_ext, 'is_valid')\n",
    "\n",
    "m = RandomForestClassifier(n_estimators=40, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "m.fit(x, y);\n",
    "m.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = rf_feat_importance(m, x)\n",
    "fi[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats=['SalesID', 'saleElapsed', 'MachineID']\n",
    "(X_train[feats]/1000).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_valid[feats]/1000).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.drop(feats, axis=1, inplace=True)\n",
    "m = RandomForestClassifier(n_estimators=40, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "m.fit(x, y);\n",
    "m.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = rf_feat_importance(m, x)\n",
    "fi[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_rf_samples(50000)\n",
    "feats=['SalesID', 'saleElapsed', 'MachineID', 'age', 'YearMade', 'saleDayofyear']\n",
    "X_train, X_valid = split_vals(df_keep, n_trn)\n",
    "m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in feats:\n",
    "\n",
    "  df_subs = df_keep.drop(f, axis=1)\n",
    "  X_train, X_valid = split_vals(df_subs, n_trn)\n",
    "  m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "  m.fit(X_train, y_train)\n",
    "  print(f)\n",
    "  print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_rf_samples()\n",
    "df_subs = df_keep.drop(['SalesID', 'MachineID', 'saleDayofyear'],axis=1)\n",
    "X_train, X_valid = split_vals(df_subs, n_trn)\n",
    "m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_estimators=160, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "%time m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest from Scratch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.imports import *\n",
    "from fastai.structured import *\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "from IPython.display import display\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"data/bulldozers/\"\n",
    "\n",
    "df_raw = pd.read_feather('tmp/bulldozers-raw')\n",
    "df_trn, y_trn, nas = proc_df(df_raw, 'SalePrice')\n",
    "def split_vals(a,n): return a[:n], a[n:]\n",
    "\n",
    "n_valid = 12000\n",
    "n_trn = len(df_trn)-n_valid\n",
    "\n",
    "X_train, X_valid = split_vals(df_trn, n_trn)\n",
    "y_train, y_valid = split_vals(y_trn, n_trn)\n",
    "raw_train, raw_valid = split_vals(df_raw, n_trn)\n",
    "x_sub = X_train[['YearMade', 'MachineHoursCurrentMeter']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeEnsemble():\n",
    "   def __init__(self, x, y, n_trees, sample_sz, min_leaf=5):\n",
    "       np.random.seed(42)\n",
    "       self.x,self.y,self.sample_sz,self.min_leaf = x,y,sample_sz,min_leaf\n",
    "       self.trees = [self.create_tree() for i in range(n_trees)]\n",
    "\n",
    "   def create_tree(self):\n",
    "       rnd_idxs = np.random.permutation(len(self.y))[:self.sample_sz]\n",
    "       return DecisionTree(self.x.iloc[rnd_idxs], self.y[rnd_idxs], min_leaf=self.min_leaf)\n",
    "       \n",
    "   def predict(self, x):\n",
    "       return np.mean([t.predict(x) for t in self.trees], axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "   def __init__(self, x, y, idxs=None, min_leaf=5):\n",
    "       if idxs is None: idxs=np.arange(len(y))\n",
    "       self.x,self.y,self.idxs,self.min_leaf = x,y,idxs,min_leaf\n",
    "       self.n,self.c = len(idxs), x.shape[1]\n",
    "       self.val = np.mean(y[idxs])\n",
    "       self.score = float('inf')\n",
    "       self.find_varsplit()\n",
    "       \n",
    "   # This just does one decision; we'll make it recursive later\n",
    "   def find_varsplit(self):\n",
    "       for i in range(self.c): self.find_better_split(i)\n",
    "           \n",
    "   # We'll write this later!\n",
    "   def find_better_split(self, var_idx): pass\n",
    "   \n",
    "   @property\n",
    "   def split_name(self): return self.x.columns[self.var_idx]\n",
    "   \n",
    "   @property\n",
    "   def split_col(self): return self.x.values[self.idxs,self.var_idx]\n",
    "\n",
    "   @property\n",
    "   def is_leaf(self): return self.score == float('inf')\n",
    "   \n",
    "   def __repr__(self):\n",
    "       s = f'n: {self.n}; val:{self.val}'\n",
    "       if not self.is_leaf:\n",
    "           s += f'; score:{self.score}; split:{self.split}; var:{self.split_name}'\n",
    "       return s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
